1. Directory Structure
css
Copy
roles/
└── upgrade_websphere
    ├── defaults
    │   └── main.yml
    ├── tasks
    │   └── main.yml
    └── handlers
        ├── main.yml
        ├── stop_appservers.yml
        ├── stop_nodeagent.yml
        ├── stop_dmgr.yml
        ├── stop_httpserver.yml
        ├── start_dmgr.yml
        ├── start_nodeagent.yml
        ├── start_appservers.yml
        ├── start_httpserver.yml
        ├── check_httpserver_status.yml
        └── start_httpserver_status.yml
2. Features & Overall Flow
Variable-Based and Filtered Paths:

For application servers and nodeagents, commands are run from:
{{ websphere_install_root }}/profiles/*-w/bin/
For DMGR tasks, commands are run from:
{{ websphere_install_root }}/profiles/*dm/bin/
Conditional Execution:
The role runs on hosts where is_appserver: true. DMGR tasks run when is_dmgr: true, and IHS tasks run when is_ihs: true.

Service Stop/Start Order and Validation:

Stop Phase:
Application servers are gathered (via serverStatus.sh), ordered in reverse (App, then Sup, then ME, with any extra servers appended), and stopped.
The NodeAgent is stopped next.
DMGR (if applicable) is stopped.
IHS is stopped (with a retry mechanism).
After each stop command, the handler validates that the service is down.
Start Phase:
DMGR is started first (if applicable).
The NodeAgent is started next.
Application servers are started (ordered as ME, then Sup, then App, with extras appended).
IHS is started.
Each start handler then validates that the service is running.
Extra IHS Handlers:
Two extra handlers (check_httpserver_status.yml and start_httpserver_status.yml) are defined for additional IHS checks, but they are not automatically called.

Customization:
Optional filters (target_server and target_group) and a kill_timeout variable are provided.

Listen on Each Task:
Instead of placing listen: at the block level, each individual task in the handler files has a listen: attribute with the appropriate handler name (e.g. listen: stop_appservers).

3. Complete File Contents
A. defaults/main.yml
yaml
Copy
---
# roles/upgrade_websphere/defaults/main.yml

# Default kill timeout in seconds (e.g., 1200 = 20 minutes)
kill_timeout: 1200

# Optional filters for application servers; leave empty to operate on all.
target_server: ""
target_group: ""
B. tasks/main.yml
yaml
Copy
---
# roles/upgrade_websphere/tasks/main.yml

- block:
    - name: Stop all services
      debug:
        msg: "Notifying handlers to stop application servers, NodeAgent and DMGR..."
      notify:
        - stop_appservers
        - stop_nodeagent
        - stop_dmgr

    - name: Stop IBM HTTP Server
      debug:
        msg: "Notifying handler to stop IBM HTTP Server..."
      notify:
        - stop_httpserver
      when: is_ihs | bool

    - name: Perform upgrade and validation tasks
      debug:
        msg: "Performing upgrade tasks and validations..."
      # Replace this with your actual upgrade/validation commands

    - name: Start all services
      debug:
        msg: "Notifying handlers to start DMGR, NodeAgent and application servers..."
      notify:
        - start_dmgr
        - start_nodeagent
        - start_appservers

    - name: Start IBM HTTP Server
      debug:
        msg: "Notifying handler to start IBM HTTP Server..."
      notify:
        - start_httpserver
      when: is_ihs | bool

  when: is_appserver | bool
C. handlers/main.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/main.yml

- import_tasks: stop_appservers.yml
- import_tasks: stop_nodeagent.yml
- import_tasks: stop_dmgr.yml
- import_tasks: stop_httpserver.yml
- import_tasks: start_dmgr.yml
- import_tasks: start_nodeagent.yml
- import_tasks: start_appservers.yml
- import_tasks: start_httpserver.yml
- import_tasks: check_httpserver_status.yml
- import_tasks: start_httpserver_status.yml
D. handlers/stop_appservers.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/stop_appservers.yml

- name: Gather running application servers for stop
  listen: stop_appservers
  shell: "{{ websphere_install_root }}/profiles/*-w/bin/serverStatus.sh -all"
  register: ws_status_stop
  when: (target_server | default('')) == "" and (target_group | default('')) == ""

- name: Set regex for running application servers (to stop)
  listen: stop_appservers
  set_fact:
    status_regex: "is STARTED"
  when: (target_server | default('')) == "" and (target_group | default('')) == ""

- name: Filter lines matching running application servers
  listen: stop_appservers
  set_fact:
    target_lines: "{{ ws_status_stop.stdout_lines | select('search', status_regex) | list }}"
  when: (target_server | default('')) == "" and (target_group | default('')) == ""

- name: Build list of running application server names
  listen: stop_appservers
  set_fact:
    target_servers: >-
      {{
        target_lines
        | map('regex_findall', 'The Application Server \"([^\"]+)\"')
        | map('first')
        | reject('equalto', None)
        | list
      }}
  when: (target_server | default('')) == "" and (target_group | default('')) == ""

- name: Order application servers for stop (reverse order: App, then Sup, then ME, then extra)
  listen: stop_appservers
  set_fact:
    sorted_servers: >-
      {{
        (target_servers | select('match', '^AppClusterMember') | list) +
        (target_servers | select('match', '^SupClusterMember') | list) +
        (target_servers | select('match', '^MEClusterMember') | list) +
        (target_servers | reject('match', '^(MEClusterMember|SupClusterMember|AppClusterMember)') | list)
      }}
  when: (target_server | default('')) == "" and (target_group | default('')) == ""

- name: Set sorted_servers for individual target application server
  listen: stop_appservers
  set_fact:
    sorted_servers: [ "{{ target_server }}" ]
  when: (target_server | default('')) != ""

- name: Filter sorted_servers by target group if defined (application servers)
  listen: stop_appservers
  set_fact:
    sorted_servers: "{{ sorted_servers | select('match', '^' ~ target_group ~ 'ClusterMember') | list }}"
  when: (target_group | default('')) != ""

- name: Stop application servers
  listen: stop_appservers
  shell: |
    {{ websphere_install_root }}/profiles/*-w/bin/stopServer.sh {{ server }}
    counter=0
    while ps -ef | grep -v grep | grep -q "{{ server }}"; do
      sleep 10
      counter=$((counter+10))
      if [ $counter -ge {{ kill_timeout }} ]; then
        echo "Application server {{ server }} still running after {{ kill_timeout }} seconds. Killing process..."
        ps -ef | grep -v grep | grep "{{ server }}" | awk '{print $2}' | xargs kill -9 || true
        break
      fi
    done
  args:
    executable: /bin/bash
  loop: "{{ sorted_servers }}"
  loop_control:
    loop_var: server
  when: sorted_servers is defined and (sorted_servers | length > 0)

- name: Validate application servers are stopped
  listen: stop_appservers
  shell: "{{ websphere_install_root }}/profiles/*-w/bin/serverStatus.sh -all"
  register: validate_stop_appservers
  changed_when: false

- name: Fail if any application server is still running
  listen: stop_appservers
  fail:
    msg: "Application servers are still running: {{ validate_stop_appservers.stdout }}"
  when: "'is STARTED' in validate_stop_appservers.stdout"
E. handlers/stop_nodeagent.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/stop_nodeagent.yml

- name: Stop the NodeAgent
  listen: stop_nodeagent
  shell: "{{ websphere_install_root }}/profiles/*-w/bin/stopNode.sh"
  args:
    executable: /bin/bash

- name: Validate NodeAgent is stopped
  listen: stop_nodeagent
  shell: "{{ websphere_install_root }}/profiles/*-w/bin/serverStatus.sh -all | grep -i nodeagent"
  register: validate_stop_nodeagent
  changed_when: false

- name: Fail if NodeAgent is still running
  listen: stop_nodeagent
  fail:
    msg: "NodeAgent is still running: {{ validate_stop_nodeagent.stdout }}"
  when: validate_stop_nodeagent.stdout is defined and ("is STARTED" in validate_stop_nodeagent.stdout)
F. handlers/stop_dmgr.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/stop_dmgr.yml

- name: Gather Deployment Manager status for stop
  listen: stop_dmgr
  shell: "{{ websphere_install_root }}/profiles/*dm/bin/serverStatus.sh -all"
  register: dmgr_status_stop
  when: is_dmgr | bool

- name: Check if Deployment Manager is running (for stop)
  listen: stop_dmgr
  set_fact:
    dmgr_running: "{{ (dmgr_status_stop.stdout_lines | select('search', 'The Deployment Manager \"dmgr\" is STARTED') | list | length) > 0 }}"
  when: is_dmgr | bool

- name: Stop the Deployment Manager
  listen: stop_dmgr
  shell: "{{ websphere_install_root }}/profiles/*dm/bin/stopManager.sh"
  args:
    executable: /bin/bash
  when: is_dmgr | bool and dmgr_running

- name: Validate DMGR is stopped
  listen: stop_dmgr
  shell: "{{ websphere_install_root }}/profiles/*dm/bin/serverStatus.sh -all"
  register: validate_stop_dmgr
  changed_when: false
  when: is_dmgr | bool

- name: Fail if DMGR is still running
  listen: stop_dmgr
  fail:
    msg: "DMGR is still running: {{ validate_stop_dmgr.stdout }}"
  when: is_dmgr | bool and ("The Deployment Manager \"dmgr\" is STARTED" in validate_stop_dmgr.stdout)
G. handlers/stop_httpserver.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/stop_httpserver.yml

- name: Stop IBM HTTP Server and validate it is down
  listen: stop_httpserver
  shell: >
    {{ ihs_install_root }}/bin/apachectl -d {{ ihs_install_root }} -f {{ ihs_install_root }}/conf/{{ ihs_instance }} -k stop;
    sleep 30;
    ps -ef | grep httpd | grep '{{ ihs_instance }}' || true
  register: stop_httpserver_result
  retries: 3
  delay: 30
  until: stop_httpserver_result.stdout | trim == ""
  args:
    executable: /bin/bash
H. handlers/start_dmgr.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/start_dmgr.yml

- name: Gather Deployment Manager status for start
  listen: start_dmgr
  shell: "{{ websphere_install_root }}/profiles/*dm/bin/serverStatus.sh -all"
  register: dmgr_status_start
  when: is_dmgr | bool

- name: Check if Deployment Manager is stopped (for start)
  listen: start_dmgr
  set_fact:
    dmgr_stopped: "{{ (dmgr_status_start.stdout_lines | select('search', 'The Deployment Manager \"dmgr\" is STOPPED') | list | length) > 0 }}"
  when: is_dmgr | bool

- name: Start the Deployment Manager
  listen: start_dmgr
  shell: "{{ websphere_install_root }}/profiles/*dm/bin/startManager.sh"
  args:
    executable: /bin/bash
  when: is_dmgr | bool and dmgr_stopped

- name: Validate DMGR is started
  listen: start_dmgr
  shell: "{{ websphere_install_root }}/profiles/*dm/bin/serverStatus.sh -all"
  register: validate_start_dmgr
  changed_when: false
  when: is_dmgr | bool

- name: Fail if DMGR is not started
  listen: start_dmgr
  fail:
    msg: "DMGR is not started: {{ validate_start_dmgr.stdout }}"
  when: is_dmgr | bool and ("The Deployment Manager \"dmgr\" is STARTED" not in validate_start_dmgr.stdout)
I. handlers/start_nodeagent.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/start_nodeagent.yml

- name: Start the NodeAgent
  listen: start_nodeagent
  shell: "{{ websphere_install_root }}/profiles/*-w/bin/startNode.sh"
  args:
    executable: /bin/bash

- name: Validate NodeAgent is started
  listen: start_nodeagent
  shell: "{{ websphere_install_root }}/profiles/*-w/bin/serverStatus.sh -all | grep -i nodeagent"
  register: validate_start_nodeagent
  changed_when: false

- name: Fail if NodeAgent is not started
  listen: start_nodeagent
  fail:
    msg: "NodeAgent is not started: {{ validate_start_nodeagent.stdout }}"
  when: validate_start_nodeagent.stdout is not defined or ("is STARTED" not in validate_start_nodeagent.stdout)
J. handlers/start_appservers.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/start_appservers.yml

- name: Gather stopped application servers for start
  listen: start_appservers
  shell: "{{ websphere_install_root }}/profiles/*-w/bin/serverStatus.sh -all"
  register: ws_status_start

- name: Set regex for stopped application servers (to start)
  listen: start_appservers
  set_fact:
    status_regex: "cannot be reached"

- name: Filter lines matching stopped application servers
  listen: start_appservers
  set_fact:
    target_lines: "{{ ws_status_start.stdout_lines | select('search', status_regex) | list }}"

- name: Build list of stopped application server names
  listen: start_appservers
  set_fact:
    target_servers: >-
      {{
        target_lines
        | map('regex_findall', 'The Application Server \"([^\"]+)\"')
        | map('first')
        | reject('equalto', None)
        | list
      }}

- name: Order application servers for start (order: ME, then Sup, then App, then extra)
  listen: start_appservers
  set_fact:
    sorted_servers: >-
      {{
        (target_servers | select('match', '^MEClusterMember') | list) +
        (target_servers | select('match', '^SupClusterMember') | list) +
        (target_servers | select('match', '^AppClusterMember') | list) +
        (target_servers | reject('match', '^(MEClusterMember|SupClusterMember|AppClusterMember)') | list)
      }}
  when: (target_server | default('')) == "" and (target_group | default('')) == ""

- name: Set sorted_servers for individual target application server
  listen: start_appservers
  set_fact:
    sorted_servers: [ "{{ target_server }}" ]
  when: (target_server | default('')) != ""

- name: Filter sorted_servers by target group if defined (application servers)
  listen: start_appservers
  set_fact:
    sorted_servers: "{{ sorted_servers | select('match', '^' ~ target_group ~ 'ClusterMember') | list }}"
  when: (target_group | default('')) != ""

- name: Start application servers
  listen: start_appservers
  shell: "{{ websphere_install_root }}/profiles/*-w/bin/startServer.sh {{ server }}"
  loop: "{{ sorted_servers }}"
  loop_control:
    loop_var: server
  when: sorted_servers is defined and (sorted_servers | length > 0)

- name: Validate application servers are started
  listen: start_appservers
  shell: "{{ websphere_install_root }}/profiles/*-w/bin/serverStatus.sh -all"
  register: validate_start_appservers
  changed_when: false

- name: Fail if application servers are not started
  listen: start_appservers
  fail:
    msg: "Application servers are not started as expected: {{ validate_start_appservers.stdout }}"
  when: "'is STARTED' not in validate_start_appservers.stdout"
K. handlers/start_httpserver.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/start_httpserver.yml

- name: Start IBM HTTP Server
  listen: start_httpserver
  shell: "{{ ihs_install_root }}/bin/apachectl -d {{ ihs_install_root }} -f {{ ihs_install_root }}/conf/{{ ihs_instance }} -k start"
  args:
    executable: /bin/bash

- name: Validate IBM HTTP Server is started
  listen: start_httpserver
  shell: "ps -ef | grep httpd | grep '{{ ihs_instance }}'"
  register: validate_start_ihs
  changed_when: false

- name: Fail if IBM HTTP Server is not started
  listen: start_httpserver
  fail:
    msg: "IBM HTTP Server is not started: {{ validate_start_ihs.stdout }}"
  when: validate_start_ihs.stdout == ""
L. handlers/check_httpserver_status.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/check_httpserver_status.yml

- name: Check IBM HTTP Server status using ps command
  listen: check_httpserver_status
  shell: "ps -ef | grep httpd | grep '{{ ihs_instance }}'"
  register: ihs_status_check
  changed_when: false

- name: Debug IBM HTTP Server check status
  listen: check_httpserver_status
  debug:
    msg: "IBM HTTP Server check status: {{ ihs_status_check.stdout }}"
M. handlers/start_httpserver_status.yml
yaml
Copy
---
# roles/upgrade_websphere/handlers/start_httpserver_status.yml

- name: Check if IBM HTTP Server is running
  listen: start_httpserver_status
  shell: "ps -ef | grep httpd | grep '{{ ihs_instance }}'"
  register: ihs_check_status
  changed_when: false

- name: Debug IBM HTTP Server status before starting
  listen: start_httpserver_status
  debug:
    msg: "IBM HTTP Server status: {{ ihs_check_status.stdout }}"

- name: Start IBM HTTP Server if not running
  listen: start_httpserver_status
  shell: "{{ ihs_install_root }}/bin/apachectl -d {{ ihs_install_root }} -f {{ ihs_install_root }}/conf/{{ ihs_instance }} -k start"
  args:
    executable: /bin/bash
  when: ihs_check_status.stdout == ""
How to Use This Role
Set Group Variables:

Set is_appserver: true on hosts where the upgrade should run.
For DMGR hosts, set is_dmgr: true.
For hosts managing IBM HTTP Server, set is_ihs: true.
Define:
websphere_install_root (e.g., "/opt/websphere")
ihs_install_root (e.g., "/opt/ihs")
ihs_instance (e.g., "bpm-httpd.conf") in your inventory or group_vars.
Call the Role in Your Playbook:
Example:

yaml
Copy
- hosts: websphere_servers
  roles:
    - role: upgrade_websphere
      vars:
        kill_timeout: 1500
        websphere_install_root: "/opt/websphere"
        ihs_install_root: "/opt/ihs"
        ihs_instance: "bpm-httpd.conf"
Handler Notifications:
When a task notifies (for example, notify: stop_appservers), Ansible will trigger all tasks in the corresponding handler file that have a matching listen: stop_appservers attribute.

Extra IHS Handlers:
The extra handlers check_httpserver_status and start_httpserver_status are available for additional checks if needed but are not automatically called.

This complete role now includes the updated sorting logic (to include extra servers), uses reject('equalto', None) in place of select('truthy'), and has each handler task include its own listen: attribute for Ansible 2.9.2. This version should be fully runnable in your environment.
